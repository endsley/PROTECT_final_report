{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if os.path.exists('/home/chieh/code/wPlotLib'):\n",
    "\tsys.path.insert(0,'/home/chieh/code/wPlotLib')\n",
    "if os.path.exists('/home/chieh/code/wuML'):\n",
    "\tsys.path.insert(0,'/home/chieh/code/wuML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj_tools import *\n",
    "import wuml\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_threshold = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penultimate layer of CE is the input of MSE with batch normalization<br>\n",
    "Denoising autoencoder is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_printing(all_losses, epoch, lr):\n",
    "\tif epoch > 1: wuml.clear_previous_line(10)\n",
    "#\n",
    "\t[total_loss, L1 , L2 , L3 , C1 , C2 , β, α] = all_losses\n",
    "\ttxt = '\\tepoch: %d\\n'%epoch\n",
    "\ttxt += '\\tlr: %.10f\\n'%lr\n",
    "\ttxt += '\\tTotal Loss: %.4f\\n'%total_loss\n",
    "\ttxt += '\\tMSE Loss: %.4f\\n'%L2\n",
    "\ttxt += '\\tCE Loss: %.4f\\n'%L3\n",
    "\ttxt += '\\tReconstruct Loss: %.4f\\n'%L1\n",
    "\ttxt += '\\tAbove 42 error: %.4f\\n'%C1\n",
    "\ttxt += '\\tBelow 22 error: %.4f\\n'%C2\n",
    "\ttxt += '\\tType I error: %.4f\\n'%α\n",
    "\ttxt += '\\tType II error: %.4f\\n'%β\n",
    "#\n",
    "\twuml.write_to_current_line(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also control the behavior of the network on call<br>\n",
    "after creating cNet = wuml.combinedNetwork(...)<br>\n",
    "define this allows you to call cNet(some_data) and return a behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ŷc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prob \u001b[38;5;241m=\u001b[39m wuml\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mŷᶜ\u001b[49m)\n\u001b[1;32m      2\u001b[0m _, ŷᶜ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(ŷᶜ, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [ŷᶜ, prob, ŷᴰ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ŷc' is not defined"
     ]
    }
   ],
   "source": [
    "\tprob = wuml.softmax(ŷᶜ)\n",
    "\t_, ŷᶜ = torch.max(ŷᶜ, 1)\n",
    "\treturn [ŷᶜ, prob, ŷᴰ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_behavior_on_call(all_data, all_networks):\n",
    "\tenc = all_networks[0]\n",
    "\tdec = all_networks[1]\n",
    "\tce_net = all_networks[2]\n",
    "\tmse_net = all_networks[3]\n",
    "#\n",
    "\t#\tthe 1st 3 items of all_data will always be X, y, index\n",
    "\t#\tthe rest will be what you include\n",
    "\tX = all_data[0]\n",
    "\ty = all_data[1]\t\t\t\t# MSE label\n",
    "#\n",
    "\t# run data through the networks\n",
    "\tŷᴬ = enc(X)\n",
    "\tŷᴮ = dec(ŷᴬ)\n",
    "\tŷᶜ = ce_net(ŷᴬ)\n",
    "\n",
    "\tŷᴰ = torch.clamp(mse_net(ŷᴬ).squeeze(), min=23, max=41)\n",
    "\t#ŷᴰ = torch.clamp(mse_net(ŷᶜ).squeeze(), min=23, max=41)\t\t# use ce output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(all_data, all_networks):\t\n",
    "\tenc = all_networks[0]\n",
    "\tdec = all_networks[1]\n",
    "\tce_net = all_networks[2]\n",
    "\tmse_net = all_networks[3]\n",
    "#\n",
    "\t#\tthe 1st 3 items of all_data will always be X, y, index\n",
    "\t#\tthe rest will be what you include\n",
    "\tX = all_data[0]\n",
    "\ty = all_data[1]\t\t\t\t# MSE label\n",
    "\tindx = all_data[2]\n",
    "\ty2= all_data[3].squeeze()\t\t\t\t# CE label\n",
    "#\n",
    "\tmsk = (torch.rand(X.shape) < denoising_threshold).long()\n",
    "\tmsk = wuml.ensure_tensor(msk, dataType=torch.FloatTensor)\n",
    "\tXin = torch.mul(X, msk)\n",
    "#\n",
    "\t# run data through the networks\n",
    "\tŷᴬ = enc(Xin)\n",
    "\tŷᴮ = dec(ŷᴬ)\n",
    "\tŷᶜ = ce_net(ŷᴬ)\n",
    "\tŷᴰ = mse_net(ŷᴬ).squeeze()\n",
    "\t#ŷᴰ = mse_net(ŷᶜ).squeeze()\t\t# use ce output\n",
    "#\n",
    "\tn = X.shape[0]\n",
    "\td = X.shape[1]\n",
    "\trelu = nn.ReLU()\n",
    "#\n",
    "\tL1 = 1*1.0*wuml.MSELoss(X, ŷᴮ)\t\t\t\t\t\t\t\t\t\t# autoencoder reconstruction loss\n",
    "\tL2 = 1*wuml.MSELoss(y, ŷᴰ)\t\t\t\t\t\t\t\t\t\t\t\t# Regression loss\n",
    "\tL3 = 1*1*wuml.CrossEntropyLoss(y2, ŷᶜ)\t\t\t\t\t\t\t\t# CE loss\n",
    "\tC1 = 1*2.2*torch.sum(relu((ŷᴰ - 42)))/n\t\t\t\t\t\t\t\t# if prediction above 43, its wrong Constraint\n",
    "\tC2 = 1*2.2*torch.sum(relu((23 - ŷᴰ))/n)\t\t\t\t\t\t\t\t# if prediction below 22, its wrong Constrain\n",
    "\tα  = 1*2.6*torch.sum(torch.mul(relu(y - 37), relu(37-ŷᴰ)))/n\t\t# if mature, penalize premature predictions type 1 error\n",
    "\tβ  = 1*2.5*torch.sum(torch.mul(relu(37-y), relu(ŷᴰ - 37)))/n\n",
    "#\n",
    "\ttotal_loss = L1 + L2 + L3 + C1 + C2 + α + β\n",
    "\treturn [total_loss, L1 , L2 , L3 , C1 , C2 , β , α]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has both regression and classification labels (3 classes)<br>\n",
    "the network will train on both labels by<br>\n",
    "\tusing the 1st network to get 3 softmax outputs, <br>\n",
    "\tfrom the 1st network, it will connect to the 2nd network, <br>\n",
    "\t\texpand to width of 5 and compress down to 1 for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wuml.wData(xpath='./data/D3_Imputed_Balanced_regression.csv', batch_size=32, \n",
    "\t\t\t\t\tlabel_type='continuous', label_column_name='gestationAge',\n",
    "\t\t\t\t\tmv_columns_to_extra_data='preterm_best',\n",
    "\t\t\t\t\tfirst_row_is_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, X_test, y_train, y_test] = wuml.split_training_test(data, test_percentage=0.2)\n",
    "X_train.Data_preprocess()\n",
    "X_test.Data_preprocess(mean=X_train.μ, std=X_train.σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_size = 40\n",
    "d = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 60\n",
    "netStructureList = []\n",
    "netStructureList.append([(width,'relu'),('bn', True),(width,'relu'),('bn', True),(width,'relu'),('bn', True),(bottleneck_size,'none')])\n",
    "netStructureList.append([(bottleneck_size,'relu'),(width,'relu'),(width,'relu'),(width,'relu'),(200,'relu'),(d,'none')])\n",
    "netStructureList.append([(2,'none')])\t#CE objective\n",
    "netStructureList.append([(width,'relu'),('bn', True),(width,'relu'),('bn', True),(1,'none')])\t#MSE objective\n",
    "netStructureList.append([(1,'none')])\t#MSE objective\n",
    "#netInputDimList = [d, bottleneck_size, bottleneck_size, 2]\n",
    "netInputDimList = [d, bottleneck_size, bottleneck_size, bottleneck_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cNet = wuml.combinedNetwork(X_train, netStructureList, netInputDimList, costFunction, \n",
    "\t\t\t\t\t\t\tmax_epoch=40, on_new_epoch_call_back=status_printing,\n",
    "\t\t\t\t\t\t\tnetwork_behavior_on_call=network_behavior_on_call, learning_rate=0.001, lr_decay_rate=0.5,\n",
    "\t\t\t\t\t\t\tY_dataType=torch.FloatTensor, extra_dataType=[torch.LongTensor]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cNet.fit()\n",
    "#y = cNet(X_train[0,:])\n",
    "#wuml.save_torch_network(cNet, './D3_' + str(width) + '_' + str(denoising_threshold) + '.pk')\n",
    "#\n",
    "#\tTraining\n",
    "[labels, prob_of_positive, gestages] = cNet(X_train, output_type='ndarray')\n",
    "display_results(X_train.Y, gestages, X_train.xDat[0], labels, prob_of_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tTest<br>\n",
    "labels, prob_of_positive, gestages] = cNet(X_test, output_type='ndarray')<br>\n",
    "isplay_results(X_test.Y, gestages, X_test.xDat[0], labels, prob_of_positive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
