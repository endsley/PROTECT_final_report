{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if os.path.exists('/home/chieh/code/wPlotLib'):\n",
    "\tsys.path.insert(0,'/home/chieh/code/wPlotLib')\n",
    "if os.path.exists('/home/chieh/code/wuML'):\n",
    "\tsys.path.insert(0,'/home/chieh/code/wuML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wuml\n",
    "from wuml.IO import *\n",
    "from precision_recall import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import wplotlib\n",
    "import torch.nn as nn\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(x, y, ŷ, ind):\n",
    "\tn = x.shape[0]\n",
    "\trelu = nn.ReLU()\n",
    "\tR = torch.sum((y - ŷ) ** 2)\n",
    "\tR3 = 10*torch.sum(relu((ŷ - 42)))\t# if prediction above 43, its wrong\n",
    "\tR4 = 10*torch.sum(relu((23 - ŷ)))\t# if prediction below 22, its wrong\n",
    "\tR5 = 50*(torch.sum(relu((ŷ - y)))*torch.sum(relu((37-y))))/(n*n)\n",
    "\tloss = R + R3 + R4 + R5\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction2(x, y, ŷ, ind):\n",
    "\tn = x.shape[0]\n",
    "\trelu = nn.ReLU()\n",
    "\tR = torch.sum((y - ŷ) ** 2)\n",
    "\tR3 = 10*torch.sum(relu((ŷ - 42)))\t# if prediction above 43, its wrong\n",
    "\tR4 = 10*torch.sum(relu((23 - ŷ)))\t# if prediction below 22, its wrong\n",
    "\tR5 = 60*(torch.sum(relu((ŷ - y)))*torch.sum(relu((37-y))))/(n*n)\n",
    "\tloss = R + R3 + R4 + R5\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction3(x, y, ŷ, ind):\n",
    "\tn = x.shape[0]\n",
    "\trelu = nn.ReLU()\n",
    "\tR = torch.sum((y - ŷ) ** 2)\n",
    "\tR3 = 10*torch.sum(relu((ŷ - 42)))\t# if prediction above 43, its wrong\n",
    "\tR4 = 10*torch.sum(relu((23 - ŷ)))\t# if prediction below 22, its wrong\n",
    "\tR5 = 80*(torch.sum(relu((ŷ - y)))*torch.sum(relu((37-y))))/(n*n)\n",
    "\tloss = R + R3 + R4 + R5\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction4(x, y, ŷ, ind):\n",
    "\tn = x.shape[0]\n",
    "\trelu = nn.ReLU()\n",
    "\tR = torch.sum((y - ŷ) ** 2)\n",
    "\tR3 = 10*torch.sum(relu((ŷ - 42)))\t# if prediction above 43, its wrong\n",
    "\tR4 = 10*torch.sum(relu((23 - ŷ)))\t# if prediction below 22, its wrong\n",
    "\tR5 = 130*(torch.sum(relu((ŷ - y)))*torch.sum(relu((37-y))))/(n*n)\n",
    "\tloss = R + R3 + R4 + R5\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction5(x, y, ŷ, ind):\n",
    "\tn = x.shape[0]\n",
    "\trelu = nn.ReLU()\n",
    "\tR = torch.sum((y - ŷ) ** 2)\n",
    "\tR3 = 10*torch.sum(relu((ŷ - 42)))\t# if prediction above 43, its wrong\n",
    "\tR4 = 10*torch.sum(relu((23 - ŷ)))\t# if prediction below 22, its wrong\n",
    "\tR5 = 160*(torch.sum(relu((ŷ - y)))*torch.sum(relu((37-y))))/(n*n)\n",
    "\tloss = R + R3 + R4 + R5\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction6(x, y, ŷ, ind):\n",
    "\tn = x.shape[0]\n",
    "\trelu = nn.ReLU()\n",
    "\tR = torch.sum((y - ŷ) ** 2)\n",
    "\tR3 = 20*torch.sum(relu((ŷ - 42)))\t# if prediction above 43, its wrong\n",
    "\tR4 = 20*torch.sum(relu((23 - ŷ)))\t# if prediction below 22, its wrong\n",
    "\tR5 = 200*(torch.sum(relu((ŷ - y)))*torch.sum(relu((37-y))))/(n*n)\n",
    "\tloss = R + R3 + R4 + R5\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wuml.wData(xpath='./data/D2_Imputed_Balanced_regression.csv', batch_size=32, \n",
    "\t\t\t\t\tlabel_type='continuous', label_column_name='gestationAge', first_row_is_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, X_test, y_train, y_test] = wuml.split_training_test(data, test_percentage=0.1)\n",
    "y_train_pre = X_train.pop_column('preterm_best')\n",
    "y_test_pre = X_test.pop_column('preterm_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.Data_preprocess()\n",
    "X_test.Data_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective 1 --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_list = [costFunction, costFunction2, costFunction3, costFunction4, costFunction5, costFunction6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch: 1360, Avg Loss: 6.4401, Learning Rate: 0.00000122"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m foo \u001b[38;5;129;01min\u001b[39;00m fun_list:\n\u001b[1;32m      2\u001b[0m \tbNet \u001b[38;5;241m=\u001b[39m wuml\u001b[38;5;241m.\u001b[39mbasicNetwork(foo, X_train, networkStructure\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;241m600\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),(\u001b[38;5;241m600\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),(\u001b[38;5;241m600\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)], max_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \t\u001b[43mbNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprint_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \t\u001b[38;5;66;03m#\tThis is the objective network output Training error\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \tẙ \u001b[38;5;241m=\u001b[39m bNet(X_train, output_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m)\t\n",
      "File \u001b[0;32m~/code/wuML/wuml/basicNetwork.py:291\u001b[0m, in \u001b[0;36mbasicNetwork.train\u001b[0;34m(self, print_status)\u001b[0m\n\u001b[1;32m    288\u001b[0m [ℓ, TL, mE, Dev] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcostFunction, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainLoader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice]\n\u001b[1;32m    289\u001b[0m [Xtype, Ytype] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_dataType, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_dataType]\n\u001b[0;32m--> 291\u001b[0m \u001b[43mrun_SGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mℓ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_dataType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_dataType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_exit_loss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_exit_loss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mon_new_epoch_call_back\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_new_epoch_call_back\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/wuML/wuml/basicNetwork.py:139\u001b[0m, in \u001b[0;36mrun_SGD\u001b[0;34m(loss_function, model_parameters, trainLoader, device, early_exit_loss_threshold, X_dataType, Y_dataType, model, lr, print_status, max_epoch, on_new_epoch_call_back)\u001b[0m\n\u001b[1;32m    136\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss): \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m    138\u001b[0m \tloss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 139\u001b[0m \t\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \tloss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    143\u001b[0m loss_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(loss_list)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/_functional.py:98\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m     97\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001b[38;5;241m=\u001b[39mmax_exp_avg_sqs[i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for foo in fun_list:\n",
    "\tbNet = wuml.basicNetwork(foo, X_train, networkStructure=[(600,'relu'),(600,'relu'),(600,'relu'),(1,'none')], max_epoch=4000, learning_rate=0.01)\n",
    "\tbNet.train(print_status=True)\n",
    "\t\n",
    "\t#\tThis is the objective network output Training error\n",
    "\tẙ = bNet(X_train, output_type='ndarray')\t\n",
    "\tprint(foo.__name__)\n",
    "\tgestational_precision_recall(ẙ, y_train_pre)\n",
    "\tres = wuml.output_regression_result(y_train, ẙ, print_out=['mean absolute error'])\n",
    "\t\n",
    "\t#\tThis is the objective network output Test error\n",
    "\tẙ = bNet(X_test, output_type='ndarray')\t\n",
    "\tgestational_precision_recall(ẙ, y_test_pre)\n",
    "\tres = wuml.output_regression_result(y_test, ẙ, print_out=['mean absolute error'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
